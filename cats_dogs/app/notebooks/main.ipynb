{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7zpl8nrQAMf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz8Q2Xfb0DX0"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nvL-yIG1CtO"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/archive/PetImages\", transform = transform)\n",
        "test_dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/archive/PetImages\", transform = transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VRHTprbP4O_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjLN0N482xuF"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZsRO0P7SPFk"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBrNuyLjBEdL"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Kpga5qD_BoS3"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xPlHyKHArbU"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FX63oVNZTaqB",
        "outputId": "2035db1d-9cd1-4660-eb2a-27ab9c97870a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 10], Step [1 / 614], Loss: 0.1289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 10], Step [101 / 614], Loss: 0.4932\n",
            "Epoch [1 / 10], Step [201 / 614], Loss: 0.0753\n",
            "Epoch [1 / 10], Step [301 / 614], Loss: 0.0459\n",
            "Epoch [1 / 10], Step [401 / 614], Loss: 0.1218\n",
            "Epoch [1 / 10], Step [501 / 614], Loss: 0.1771\n",
            "Epoch [1 / 10], Step [601 / 614], Loss: 0.0656\n",
            "Epoch [2 / 10], Step [1 / 614], Loss: 0.0735\n",
            "Epoch [2 / 10], Step [101 / 614], Loss: 0.1056\n",
            "Epoch [2 / 10], Step [201 / 614], Loss: 0.0292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2 / 10], Step [301 / 614], Loss: 0.1567\n",
            "Epoch [2 / 10], Step [401 / 614], Loss: 0.0884\n",
            "Epoch [2 / 10], Step [501 / 614], Loss: 0.0484\n",
            "Epoch [2 / 10], Step [601 / 614], Loss: 0.2492\n",
            "Epoch [3 / 10], Step [1 / 614], Loss: 0.1419\n",
            "Epoch [3 / 10], Step [101 / 614], Loss: 0.1388\n",
            "Epoch [3 / 10], Step [201 / 614], Loss: 0.0196\n",
            "Epoch [3 / 10], Step [301 / 614], Loss: 0.0333\n",
            "Epoch [3 / 10], Step [401 / 614], Loss: 0.0704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3 / 10], Step [501 / 614], Loss: 0.1901\n",
            "Epoch [3 / 10], Step [601 / 614], Loss: 0.0612\n",
            "Epoch [4 / 10], Step [1 / 614], Loss: 0.0130\n",
            "Epoch [4 / 10], Step [101 / 614], Loss: 0.0650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4 / 10], Step [201 / 614], Loss: 0.0996\n",
            "Epoch [4 / 10], Step [301 / 614], Loss: 0.0724\n",
            "Epoch [4 / 10], Step [401 / 614], Loss: 0.0519\n",
            "Epoch [4 / 10], Step [501 / 614], Loss: 0.1242\n",
            "Epoch [4 / 10], Step [601 / 614], Loss: 0.0535\n",
            "Epoch [5 / 10], Step [1 / 614], Loss: 0.2108\n",
            "Epoch [5 / 10], Step [101 / 614], Loss: 0.0569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5 / 10], Step [201 / 614], Loss: 0.0170\n",
            "Epoch [5 / 10], Step [301 / 614], Loss: 0.0935\n",
            "Epoch [5 / 10], Step [401 / 614], Loss: 0.1720\n",
            "Epoch [5 / 10], Step [501 / 614], Loss: 0.0182\n",
            "Epoch [5 / 10], Step [601 / 614], Loss: 0.1459\n",
            "Epoch [6 / 10], Step [1 / 614], Loss: 0.0276\n",
            "Epoch [6 / 10], Step [101 / 614], Loss: 0.0812\n",
            "Epoch [6 / 10], Step [201 / 614], Loss: 0.0136\n",
            "Epoch [6 / 10], Step [301 / 614], Loss: 0.0632\n",
            "Epoch [6 / 10], Step [401 / 614], Loss: 0.0128\n",
            "Epoch [6 / 10], Step [501 / 614], Loss: 0.0140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6 / 10], Step [601 / 614], Loss: 0.0364\n",
            "Epoch [7 / 10], Step [1 / 614], Loss: 0.0078\n",
            "Epoch [7 / 10], Step [101 / 614], Loss: 0.0028\n",
            "Epoch [7 / 10], Step [201 / 614], Loss: 0.0794\n",
            "Epoch [7 / 10], Step [301 / 614], Loss: 0.0089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7 / 10], Step [401 / 614], Loss: 0.0126\n",
            "Epoch [7 / 10], Step [501 / 614], Loss: 0.0090\n",
            "Epoch [7 / 10], Step [601 / 614], Loss: 0.0048\n",
            "Epoch [8 / 10], Step [1 / 614], Loss: 0.0165\n",
            "Epoch [8 / 10], Step [101 / 614], Loss: 0.0415\n",
            "Epoch [8 / 10], Step [201 / 614], Loss: 0.0253\n",
            "Epoch [8 / 10], Step [301 / 614], Loss: 0.0524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8 / 10], Step [401 / 614], Loss: 0.0561\n",
            "Epoch [8 / 10], Step [501 / 614], Loss: 0.0123\n",
            "Epoch [8 / 10], Step [601 / 614], Loss: 0.1430\n",
            "Epoch [9 / 10], Step [1 / 614], Loss: 0.0159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9 / 10], Step [101 / 614], Loss: 0.0005\n",
            "Epoch [9 / 10], Step [201 / 614], Loss: 0.0482\n",
            "Epoch [9 / 10], Step [301 / 614], Loss: 0.0025\n",
            "Epoch [9 / 10], Step [401 / 614], Loss: 0.0530\n",
            "Epoch [9 / 10], Step [501 / 614], Loss: 0.0138\n",
            "Epoch [9 / 10], Step [601 / 614], Loss: 0.0112\n",
            "Epoch [10 / 10], Step [1 / 614], Loss: 0.0576\n",
            "Epoch [10 / 10], Step [101 / 614], Loss: 0.0057\n",
            "Epoch [10 / 10], Step [201 / 614], Loss: 0.0111\n",
            "Epoch [10 / 10], Step [301 / 614], Loss: 0.0336\n",
            "Epoch [10 / 10], Step [401 / 614], Loss: 0.0456\n",
            "Epoch [10 / 10], Step [501 / 614], Loss: 0.0665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10 / 10], Step [601 / 614], Loss: 0.0089\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('Epoch [{} / {}], Step [{} / {}], Loss: {:.4f}'.format(epoch + 1, 10, i + 1, len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOH252wAIwZS"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxZ1LIv6WWyF"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for i, (images, labels) in enumerate(test_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    total += labels.size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueuX83KOXF76"
      },
      "outputs": [],
      "source": [
        "accuracy = correct / total * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaQ4-C_qXNDY",
        "outputId": "fd3ac8e3-171c-4b52-ef96-821b2c9f8ae0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64.36465495289025"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knktprajWGrA"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    return image.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qywo-q-xXVcU"
      },
      "outputs": [],
      "source": [
        "def predict(image_path):\n",
        "    model.eval()\n",
        "    image = load_image(image_path)\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "    return 'Cat' if predicted.item() == 0 else 'Dog'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECXryPsIX6vT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ooQ2qqjX1sH"
      },
      "outputs": [],
      "source": [
        "def show_image_with_prediction(image_path):\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    prediction = predict(image_path)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'Prediction: {prediction}')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5mddT0fXgjM"
      },
      "outputs": [],
      "source": [
        "image_path = '/content/drive/MyDrive/archive/test/cat.jpg'\n",
        "show_image_with_prediction(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#загрузка модели\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/model.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "UHNTHloSWd8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}